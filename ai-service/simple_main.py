from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any
import json
from datetime import datetime

app = FastAPI(
    title="AI MES Service (Simple)",
    description="Simplified AI-powered Manufacturing Execution System Analysis Service",
    version="1.0.0-simple"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš©ìœ¼ë¡œ ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class AnalysisResponse(BaseModel):
    analysis: str
    recommendations: Optional[list] = None
    alerts: Optional[list] = None
    timestamp: datetime

@app.get("/")
async def root():
    return {"status": "healthy", "message": "AI MES Service (Simple) is running", "version": "1.0.0-simple"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "message": "Service is operational", "version": "1.0.0-simple"}

@app.post("/api/analyze/chat")
async def analyze_chat_message(request: Dict[str, Any]):
    try:
        message = request.get("message", "")
        agent_type = request.get("agentType", "general")
        context_data = request.get("context")
        
        if not message.strip():
            raise HTTPException(status_code=400, detail="Message is required")
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ìƒì„±
        analysis = generate_context_analysis(message, agent_type, context_data)
        
        # ê°„ë‹¨í•œ ì¶”ì²œì‚¬í•­ê³¼ ì•Œë¦¼ ì¶”ì¶œ
        recommendations = extract_recommendations(analysis)
        alerts = extract_alerts(analysis)
        
        return AnalysisResponse(
            analysis=analysis,
            recommendations=recommendations,
            alerts=alerts,
            timestamp=datetime.now()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chat analysis failed: {str(e)}")

def generate_context_analysis(message: str, agent_type: str, context_data: Optional[Dict[str, Any]]) -> str:
    """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ìƒì„±"""
    
    if not context_data:
        return f"""ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸: "{message}"

í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì—†ì–´ ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” í™”ë©´ì˜ ë°ì´í„°ì™€ í•¨ê»˜ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.

ê¶Œì¥ì‚¬í•­:
- êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì¡°ê±´ì„ í¬í•¨í•˜ì—¬ ì§ˆë¬¸í•´ì£¼ì„¸ìš”
- íŠ¹ì • íŒ¹ì´ë‚˜ ê¸°ê°„ì„ ëª…ì‹œí•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤
"""

    page_type = context_data.get('pageType', '')
    total_count = context_data.get('totalCount', 0)
    
    if page_type == 'lot_history':
        return generate_lot_analysis(message, context_data)
    elif page_type == 'equipment_history':
        return generate_equipment_analysis(message, context_data)
    elif page_type == 'return_history':
        return generate_return_analysis(message, context_data)
    else:
        return f"""ì§ˆë¬¸: "{message}"

ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
- í˜ì´ì§€ íƒ€ì…: {page_type}
- ë°ì´í„° ìˆ˜: {total_count}ê°œ

ë” êµ¬ì²´ì ì¸ ë¶„ì„ì„ ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""

def generate_lot_analysis(message: str, context_data: Dict[str, Any]) -> str:
    """Lot ë°ì´í„° ê¸°ë°˜ ë¶„ì„"""
    lot_data = context_data.get('lotData', [])
    search_term = context_data.get('searchTerm', '')
    selected_fab = context_data.get('selectedFab', 'all')
    total_count = len(lot_data)
    
    if not lot_data:
        return f"""Lot ë¶„ì„ ê²°ê³¼

ì§ˆë¬¸: "{message}"

í˜„ì¬ ì¡°íšŒëœ Lot ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.
- ê²€ìƒ‰ì–´: {search_term}
- ì„ íƒëœ íŒ¹: {selected_fab}

ê¶Œì¥ì‚¬í•­:
- LOT ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
- ë‹¤ë¥¸ íŒ¹ì—ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
- ê²€ìƒ‰ ì¡°ê±´ì„ ë„“í˜€ì„œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
"""

    # ë°ì´í„° ë¶„ì„
    fabs = list(set(lot.get('fab', '') for lot in lot_data))
    statuses = list(set(lot.get('status', '') for lot in lot_data))
    products = list(set(lot.get('product', '') for lot in lot_data))
    
    # ìƒíƒœë³„ í†µê³„
    status_counts = {}
    for lot in lot_data:
        status = lot.get('status', 'unknown')
        status_counts[status] = status_counts.get(status, 0) + 1
    
    analysis = f"""ğŸ” Lot ë¶„ì„ ê²°ê³¼

ì§ˆë¬¸: "{message}"

ğŸ“Š í˜„ì¬ ë°ì´í„° í˜„í™©:
- ì´ Lot ìˆ˜: {total_count}ê°œ
- ê²€ìƒ‰ì–´: {search_term}
- ëŒ€ìƒ íŒ¹: {', '.join(fabs)}
- ì œí’ˆ: {', '.join(products[:3])}{'...' if len(products) > 3 else ''}

ğŸ“ˆ ìƒíƒœë³„ ë¶„í¬:"""

    for status, count in status_counts.items():
        percentage = (count / total_count) * 100
        analysis += f"\n- {translate_status(status)}: {count}ê°œ ({percentage:.1f}%)"
    
    analysis += f"""

ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:
- ê²€ìƒ‰ëœ {total_count}ê°œ Lotì˜ ìƒíƒœ ë¶„í¬ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤
- {fabs[0] if fabs else 'N/A'} íŒ¹ì—ì„œ ì£¼ë¡œ ì²˜ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤"""

    if 'completed' in status_counts and status_counts['completed'] > 0:
        completion_rate = (status_counts['completed'] / total_count) * 100
        analysis += f"\n- ì™„ë£Œìœ¨: {completion_rate:.1f}% (ì–‘í˜¸)"
    
    if 'error' in status_counts and status_counts['error'] > 0:
        error_rate = (status_counts['error'] / total_count) * 100
        analysis += f"\n- ì˜¤ë¥˜ìœ¨: {error_rate:.1f}% (ì£¼ì˜ í•„ìš”)"

    analysis += """

ğŸ¯ ê¶Œì¥ì‚¬í•­:
- ì§„í–‰ ì¤‘ì¸ Lotë“¤ì˜ ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”
- ì˜¤ë¥˜ ìƒíƒœì˜ Lotì´ ìˆë‹¤ë©´ ìš°ì„  ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤
- íŒ¹ë³„ ì²˜ë¦¬ íš¨ìœ¨ì„±ì„ ë¹„êµ ë¶„ì„í•´ë³´ì„¸ìš”"""

    return analysis

def generate_equipment_analysis(message: str, context_data: Dict[str, Any]) -> str:
    """ì„¤ë¹„ ë°ì´í„° ê¸°ë°˜ ë¶„ì„"""
    equipment_data = context_data.get('equipmentData', [])
    search_term = context_data.get('searchTerm', '')
    selected_fab = context_data.get('selectedFab', 'all')
    selected_status = context_data.get('selectedStatus', 'all')
    total_count = len(equipment_data)
    
    if not equipment_data:
        return f"""ğŸ”§ ì„¤ë¹„ ë¶„ì„ ê²°ê³¼

ì§ˆë¬¸: "{message}"

í˜„ì¬ ì¡°íšŒëœ ì„¤ë¹„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.
- ê²€ìƒ‰ì–´: {search_term}
- ì„ íƒëœ íŒ¹: {selected_fab}
- ì„ íƒëœ ìƒíƒœ: {selected_status}

ê¶Œì¥ì‚¬í•­:
- ì„¤ë¹„ ID ë˜ëŠ” ì„¤ë¹„ëª…ì„ ì •í™•íˆ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
- ë‹¤ë¥¸ íŒ¹ì—ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
- ìƒíƒœ í•„í„°ë¥¼ ë³€ê²½í•´ì„œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
"""

    # ë°ì´í„° ë¶„ì„
    fabs = list(set(eq.get('fab', '') for eq in equipment_data))
    statuses = list(set(eq.get('status', '') for eq in equipment_data))
    results = list(set(eq.get('result', '') for eq in equipment_data))
    
    # ìƒíƒœë³„ í†µê³„
    status_counts = {}
    result_counts = {}
    
    for eq in equipment_data:
        status = eq.get('status', 'unknown')
        result = eq.get('result', 'unknown')
        status_counts[status] = status_counts.get(status, 0) + 1
        result_counts[result] = result_counts.get(result, 0) + 1
    
    analysis = f"""ğŸ”§ ì„¤ë¹„ ë¶„ì„ ê²°ê³¼

ì§ˆë¬¸: "{message}"

ğŸ“Š í˜„ì¬ ì„¤ë¹„ í˜„í™©:
- ì´ ì„¤ë¹„ ìˆ˜: {total_count}ê°œ
- ê²€ìƒ‰ì–´: {search_term}
- ëŒ€ìƒ íŒ¹: {', '.join(fabs)}

ğŸ“ˆ ìƒíƒœë³„ ë¶„í¬:"""

    for status, count in status_counts.items():
        percentage = (count / total_count) * 100
        analysis += f"\n- {status}: {count}ê°œ ({percentage:.1f}%)"
    
    analysis += f"""

ğŸ¯ ê²°ê³¼ë³„ ë¶„í¬:"""

    for result, count in result_counts.items():
        percentage = (count / total_count) * 100
        analysis += f"\n- {result}: {count}ê°œ ({percentage:.1f}%)"

    analysis += f"""

ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:
- ì´ {total_count}ê°œ ì„¤ë¹„ì˜ ìš´ì˜ í˜„í™©ì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤"""

    if 'N/A' not in results and results:
        normal_count = result_counts.get('ì •ìƒ', 0)
        if normal_count > 0:
            normal_rate = (normal_count / total_count) * 100
            analysis += f"\n- ì •ìƒ ìš´ì˜ë¥ : {normal_rate:.1f}%"
        
        warning_count = result_counts.get('ê²½ê³ ', 0)
        if warning_count > 0:
            warning_rate = (warning_count / total_count) * 100
            analysis += f"\n- ê²½ê³  ìƒíƒœ: {warning_rate:.1f}% (ì ê²€ í•„ìš”)"

    analysis += """

ğŸ” ê¶Œì¥ì‚¬í•­:
- ê²½ê³  ìƒíƒœì˜ ì„¤ë¹„ëŠ” ìš°ì„ ì ìœ¼ë¡œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤
- ì„¤ë¹„ë³„ ê°€ë™ë¥ ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”
- ì •ë¹„ ìŠ¤ì¼€ì¤„ì„ ìµœì í™”í•˜ì—¬ ë‹¤ìš´íƒ€ì„ì„ ìµœì†Œí™”í•˜ì„¸ìš”"""

    return analysis

def generate_return_analysis(message: str, context_data: Dict[str, Any]) -> str:
    """ë°˜ì†¡ ë°ì´í„° ê¸°ë°˜ ë¶„ì„"""
    return_data = context_data.get('returnData', [])
    search_term = context_data.get('searchTerm', '')
    selected_fab = context_data.get('selectedFab', 'all')
    selected_severity = context_data.get('selectedSeverity', 'all')
    summary_stats = context_data.get('summaryStats', {})
    total_count = len(return_data)
    
    if not return_data:
        return f"""ğŸ”„ ë°˜ì†¡ ë¶„ì„ ê²°ê³¼

ì§ˆë¬¸: "{message}"

í˜„ì¬ ì¡°íšŒëœ ë°˜ì†¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.
- ê²€ìƒ‰ì–´: {search_term}
- ì„ íƒëœ íŒ¹: {selected_fab}
- ì„ íƒëœ ì‹¬ê°ë„: {selected_severity}

ê¶Œì¥ì‚¬í•­:
- ë°˜ì†¡ ID ë˜ëŠ” LOT ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
- ë‹¤ë¥¸ íŒ¹ì—ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
- ì‹¬ê°ë„ í•„í„°ë¥¼ ë³€ê²½í•´ì„œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
"""

    # ë°ì´í„° ë¶„ì„
    fabs = list(set(ret.get('fab', '') for ret in return_data))
    severities = list(set(ret.get('severity', '') for ret in return_data))
    reasons = list(set(ret.get('returnReason', '') for ret in return_data))
    
    analysis = f"""ğŸ”„ ë°˜ì†¡ ë¶„ì„ ê²°ê³¼

ì§ˆë¬¸: "{message}"

ğŸ“Š ë°˜ì†¡ í˜„í™© ìš”ì•½:
- ì´ ë°˜ì†¡ ê±´ìˆ˜: {summary_stats.get('totalReturns', total_count)}ê°œ
- í•´ê²°ì™„ë£Œ: {summary_stats.get('resolvedCount', 0)}ê°œ
- ì²˜ë¦¬ì¤‘: {summary_stats.get('inProgressCount', 0)}ê°œ
- High ì‹¬ê°ë„: {summary_stats.get('highSeverityCount', 0)}ê°œ

ğŸ“ˆ í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼:
- ê²€ìƒ‰ëœ ë°˜ì†¡: {total_count}ê°œ
- ëŒ€ìƒ íŒ¹: {', '.join(fabs)}
- ì‹¬ê°ë„: {', '.join(severities)}

ğŸ” ì£¼ìš” ë°˜ì†¡ ì‚¬ìœ :"""

    # ë°˜ì†¡ ì‚¬ìœ ë³„ í†µê³„ (ìƒìœ„ 5ê°œ)
    reason_counts = {}
    for ret in return_data:
        reason = ret.get('returnReason', 'unknown')
        reason_counts[reason] = reason_counts.get(reason, 0) + 1
    
    sorted_reasons = sorted(reason_counts.items(), key=lambda x: x[1], reverse=True)
    for reason, count in sorted_reasons[:5]:
        percentage = (count / total_count) * 100
        analysis += f"\n- {reason}: {count}ê±´ ({percentage:.1f}%)"

    # ì‹¬ê°ë„ ë¶„ì„
    high_severity_count = summary_stats.get('highSeverityCount', 0)
    total_returns = summary_stats.get('totalReturns', total_count)
    
    if high_severity_count > 0 and total_returns > 0:
        high_severity_rate = (high_severity_count / total_returns) * 100
        analysis += f"""

âš ï¸ ì‹¬ê°ë„ ë¶„ì„:
- High ì‹¬ê°ë„ ë¹„ìœ¨: {high_severity_rate:.1f}%"""
        
        if high_severity_rate > 20:
            analysis += " (ë†’ìŒ - ì£¼ì˜ í•„ìš”)"
        elif high_severity_rate > 10:
            analysis += " (ë³´í†µ)"
        else:
            analysis += " (ë‚®ìŒ - ì–‘í˜¸)"

    # í•´ê²°ë¥  ë¶„ì„
    resolved_count = summary_stats.get('resolvedCount', 0)
    if total_returns > 0:
        resolution_rate = (resolved_count / total_returns) * 100
        analysis += f"""

ğŸ“ˆ ì²˜ë¦¬ íš¨ìœ¨ì„±:
- í•´ê²°ë¥ : {resolution_rate:.1f}%"""
        
        if resolution_rate > 80:
            analysis += " (ìš°ìˆ˜)"
        elif resolution_rate > 60:
            analysis += " (ì–‘í˜¸)"
        else:
            analysis += " (ê°œì„  í•„ìš”)"

    analysis += """

ğŸ¯ ê¶Œì¥ì‚¬í•­:
- High ì‹¬ê°ë„ ë°˜ì†¡ì˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„ì„ ìš°ì„  ì‹¤ì‹œí•˜ì„¸ìš”
- ë°˜ë³µì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ë°˜ì†¡ ì‚¬ìœ ì— ëŒ€í•œ ì˜ˆë°©ì±…ì„ ìˆ˜ë¦½í•˜ì„¸ìš”
- íŒ¹ë³„ ë°˜ì†¡ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ê°œì„ ì ì„ ë„ì¶œí•˜ì„¸ìš”
- ë°˜ì†¡ í•´ê²° ì‹œê°„ì„ ë‹¨ì¶•í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ê²€í† í•˜ì„¸ìš”"""

    return analysis

def translate_status(status: str) -> str:
    """ìƒíƒœ ë²ˆì—­"""
    translations = {
        'completed': 'ì™„ë£Œ',
        'in_progress': 'ì§„í–‰ì¤‘',
        'waiting': 'ëŒ€ê¸°',
        'error': 'ì˜¤ë¥˜',
        'pending': 'ëŒ€ê¸°ì¤‘'
    }
    return translations.get(status, status)

def extract_recommendations(analysis: str) -> list:
    """ë¶„ì„ì—ì„œ ê¶Œì¥ì‚¬í•­ ì¶”ì¶œ"""
    recommendations = []
    lines = analysis.split('\n')
    in_recommendations = False
    
    for line in lines:
        line = line.strip()
        if 'ê¶Œì¥ì‚¬í•­' in line or 'ğŸ¯' in line:
            in_recommendations = True
            continue
        elif in_recommendations and line.startswith('-'):
            recommendations.append(line[1:].strip())
        elif in_recommendations and line and not line.startswith('-'):
            in_recommendations = False
    
    return recommendations[:5]  # ìµœëŒ€ 5ê°œ

def extract_alerts(analysis: str) -> list:
    """ë¶„ì„ì—ì„œ ì•Œë¦¼ ì¶”ì¶œ"""
    alerts = []
    lines = analysis.split('\n')
    
    for line in lines:
        line = line.strip()
        if 'ì£¼ì˜ í•„ìš”' in line or 'ê²½ê³ ' in line or 'âš ï¸' in line or 'ë†’ìŒ' in line:
            alerts.append(line)
    
    return alerts[:3]  # ìµœëŒ€ 3ê°œ

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "simple_main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
