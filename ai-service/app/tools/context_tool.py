"""
ê°„ì†Œí™”ëœ Context Tool - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë°›ì€ ë°ì´í„°ë§Œ í™œìš©
ğŸ”¥ ì‚¬ë‚´ ìˆ˜ì • í¬ì¸íŠ¸: ì‹¤ì œ ë°ì´í„° ì†ŒìŠ¤ì™€ ì—°ë™í•  ë•Œ ì´ íŒŒì¼ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤
"""

from langchain.tools import BaseTool
from typing import Type, Optional, Dict, Any
from pydantic import BaseModel, Field
import structlog
import json

logger = structlog.get_logger()

class ContextInput(BaseModel):
    """Context tool input"""
    context_type: str = Field(description="Type of context data to analyze")
    
class ContextTool(BaseTool):
    """ë‹¨ìˆœí™”ëœ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ë„êµ¬"""
    name = "context_analyzer"
    description = "í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë°›ì€ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤"
    args_schema: Type[BaseModel] = ContextInput
    context_data: Dict[str, Any] = Field(default_factory=dict)
    
    def __init__(self, context_data: Optional[Dict[str, Any]] = None, **kwargs):
        super().__init__(context_data=context_data or {}, **kwargs)
    
    def _run(self, context_type: str = "general") -> str:
        """ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ì‹¤í–‰"""
        try:
            if not self.context_data:
                return "ë¶„ì„í•  ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # í˜ì´ì§€ íƒ€ì…ì— ë”°ë¥¸ ë°ì´í„° ë¶„ì„
            page_type = self.context_data.get('pageType', '')
            
            if 'lot' in page_type.lower():
                return self._analyze_lot_context()
            elif 'equipment' in page_type.lower():
                return self._analyze_equipment_context()
            elif 'return' in page_type.lower():
                return self._analyze_return_context()
            else:
                return self._analyze_general_context()
                
        except Exception as e:
            logger.error("Context analysis error", error=str(e))
            return f"ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _analyze_lot_context(self) -> str:
        """LOT ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„"""
        lot_data = self.context_data.get('lotData', [])
        search_term = self.context_data.get('searchTerm', '')
        selected_fab = self.context_data.get('selectedFab', 'all')
        total_count = len(lot_data)
        
        # ğŸ”¥ ì‚¬ë‚´ ìˆ˜ì • í¬ì¸íŠ¸: ì‹¤ì œ LOT ë°ì´í„° ë¶„ì„ ë¡œì§ìœ¼ë¡œ ë³€ê²½
        if not lot_data:
            return f"LOT ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ì–´: {search_term}, íŒ¹: {selected_fab})"
        
        # ê¸°ë³¸ í†µê³„ ìƒì„±
        fabs = list(set(lot.get('fab', '') for lot in lot_data))
        statuses = list(set(lot.get('status', '') for lot in lot_data))
        products = list(set(lot.get('product', '') for lot in lot_data))
        
        result = f"""ğŸ“Š LOT ë°ì´í„° ë¶„ì„ ê²°ê³¼:
ì´ LOT ìˆ˜: {total_count}ê°œ
íŒ¹: {', '.join(fabs)}
ìƒíƒœ: {', '.join(statuses)}
ì œí’ˆ: {', '.join(products[:3])}{'...' if len(products) > 3 else ''}

ì£¼ìš” LOT ì •ë³´:"""
        
        # ìƒìœ„ 5ê°œ LOT ì •ë³´ í‘œì‹œ
        for i, lot in enumerate(lot_data[:5]):
            result += f"\n{i+1}. {lot.get('lotNumber', 'N/A')}: {lot.get('product', 'N/A')} ({lot.get('fab', 'N/A')}) - {lot.get('status', 'N/A')}"
        
        if total_count > 5:
            result += f"\n... ì™¸ {total_count - 5}ê°œ"
            
        return result
    
    def _analyze_equipment_context(self) -> str:
        """ì„¤ë¹„ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„"""
        equipment_data = self.context_data.get('equipmentData', [])
        search_term = self.context_data.get('searchTerm', '')
        selected_fab = self.context_data.get('selectedFab', 'all')
        selected_status = self.context_data.get('selectedStatus', 'all')
        total_count = len(equipment_data)
        
        # ğŸ”¥ ì‚¬ë‚´ ìˆ˜ì • í¬ì¸íŠ¸: ì‹¤ì œ ì„¤ë¹„ ë°ì´í„° ë¶„ì„ ë¡œì§ìœ¼ë¡œ ë³€ê²½
        if not equipment_data:
            return f"ì„¤ë¹„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ì–´: {search_term}, íŒ¹: {selected_fab}, ìƒíƒœ: {selected_status})"
        
        fabs = list(set(eq.get('fab', '') for eq in equipment_data))
        statuses = list(set(eq.get('status', '') for eq in equipment_data))
        
        result = f"""ğŸ”§ ì„¤ë¹„ ë°ì´í„° ë¶„ì„ ê²°ê³¼:
ì´ ì„¤ë¹„ ìˆ˜: {total_count}ê°œ
íŒ¹: {', '.join(fabs)}
ìƒíƒœ: {', '.join(statuses)}

ì£¼ìš” ì„¤ë¹„ ì •ë³´:"""
        
        for i, eq in enumerate(equipment_data[:5]):
            result += f"\n{i+1}. {eq.get('equipmentId', 'N/A')}: {eq.get('fab', 'N/A')} - {eq.get('status', 'N/A')}"
        
        if total_count > 5:
            result += f"\n... ì™¸ {total_count - 5}ê°œ"
            
        return result
    
    def _analyze_return_context(self) -> str:
        """ë°˜ì†¡ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„"""
        return_data = self.context_data.get('returnData', [])
        summary_stats = self.context_data.get('summaryStats', {})
        search_term = self.context_data.get('searchTerm', '')
        selected_fab = self.context_data.get('selectedFab', 'all')
        total_count = len(return_data)
        
        # ğŸ”¥ ì‚¬ë‚´ ìˆ˜ì • í¬ì¸íŠ¸: ì‹¤ì œ ë°˜ì†¡ ë°ì´í„° ë¶„ì„ ë¡œì§ìœ¼ë¡œ ë³€ê²½
        if not return_data:
            return f"ë°˜ì†¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ì–´: {search_term}, íŒ¹: {selected_fab})"
        
        result = f"""ğŸ”„ ë°˜ì†¡ ë°ì´í„° ë¶„ì„ ê²°ê³¼:
ì´ ë°˜ì†¡ ê±´ìˆ˜: {summary_stats.get('totalReturns', total_count)}ê°œ
í•´ê²°ì™„ë£Œ: {summary_stats.get('resolvedCount', 0)}ê°œ
ì²˜ë¦¬ì¤‘: {summary_stats.get('inProgressCount', 0)}ê°œ
High ì‹¬ê°ë„: {summary_stats.get('highSeverityCount', 0)}ê°œ

ì£¼ìš” ë°˜ì†¡ ì •ë³´:"""
        
        for i, ret in enumerate(return_data[:5]):
            result += f"\n{i+1}. {ret.get('returnId', 'N/A')}: {ret.get('severity', 'N/A')} - {ret.get('status', 'N/A')}"
        
        if total_count > 5:
            result += f"\n... ì™¸ {total_count - 5}ê°œ"
            
        return result
    
    def _analyze_general_context(self) -> str:
        """ì¼ë°˜ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        return f"ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°: {json.dumps(self.context_data, ensure_ascii=False, indent=2)}"
